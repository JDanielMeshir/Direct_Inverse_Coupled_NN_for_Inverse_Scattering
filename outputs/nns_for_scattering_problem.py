# -*- coding: utf-8 -*-
"""NNs_for_Scattering_Problem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvcxcR0IqGDXuCeC6mqN5xueHISbcI9F

# A direct-then-inverse coupled artificial neural network for the acoustic inverse scattering problem
"""

# -*- coding: utf-8 -*-
"""NN_pythorch.ipynb
by JDMV
"""

#import packages
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import OrderedDict

import time

# fixed the random seed
np.random.seed(73)


# CUDA support
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')

print(device)

"""We loaded two neural networks (NNs) with `Cople_NN`: DNN, the direct NN trained in the offline step, and INN, the inverse NN that will be trained in the online step.

Recall that the direct NN was trained with four different shapes: Circles, Ellipses, Kites, and Virus shapes. Therefore, if you need to reconstruct another shape, the direct NN must be retrained to learn the far-field pattern of that specific boundary form.

The offline step involves the trained neural network $\mathcal{D$}, which maps boundary points to their corresponding far-field pattern measurements. We also selected 64 evenly spaced incident wave directions for the training data. Consequently, for each shape, we created 64 'X' data samples, with each sample represented as a vector. The first component of each vector indicates the incident wave's angle direction, while the remaining 128 components represent the 64 boundary points, with both x and y coordinates included. As a result, the 'X' data has a shape of (64000, 129). This data can be found in ______ (please specify where).

On the other hand, we used the Nystrom method to generate the associated far-field patterns for each 'X' data sample. These far-field pattern measurements are stored in the 'Y' vector, which has a shape of (64000, 128). In this case, the number 128 represents the 64 measurements of the far-field pattern, including both real and imaginary parts for each direction.



"""

from Couple_NN import *

"""For test cases we used three cases Case1, Case2 and Case3."""

#Load the data
torch.manual_seed(73)
np.random.seed(73)


#Load the far-field pattern with 64 measurements, split into real and imaginary parts.
# with this far-field patter we will to reconstruc the shape in the online step
testcase=np.load('u_inf_Case3.npy') # you can change the test case for 1, 2 or 3


#Load the real boundary
boundarytest=np.load('boundarytestcase3.npy')


# Number of incident wave directions. (Maximum 64)
npts=8

directions=np.linspace(0,2.0*np.pi*(npts-1.0)/npts,npts,endpoint=True)
ds=directions.shape
directions=directions.reshape(ds[0],1)

t=np.linspace(0,2.0*np.pi*(64-1.0)/64,64,endpoint=True)

params=np.array([t for  i in range(len(directions))])


# add noise to the far-field pattern data.
sigma_ruido=0.01*max(abs(testcase[0])) # 1% of noise

testcase_noise=testcase +np.random.normal(0,sigma_ruido,(64,128))

#We select the far field pattern for each direction of incidence

testcase_noise=testcase_noise[::int(64/npts)]

# Set our inverse NN
# The last layer contains the number of parameters to be recovered for the display form.

layers=[64,64,128,64,10] #11 [a_0,...,a_5,b_1,...,b5,h,k]
activations=[torch.nn.Tanh,torch.nn.Tanh,torch.nn.Tanh,torch.nn.Identity]

inverse_NN=INN(layers,activations)

#Online step. We can choose the form of representation (cosine or Fourier series)
#%%time

inverse_NN.train(params,testcase_noise,directions,representation='Cosine_series',
                 lamb1=0,lamb2=0)

coeficients_predicted,boundary_predicted=inverse_NN.predict(params)

plt.plot(boundary_predicted[:,0],boundary_predicted[:,1],'^-',color='dimgray',
         label='Shape predicted')


plt.plot(boundarytest[1::2],boundarytest[2::2],'o-',color='black',
         label='real shape',markersize=2.5)

plt.axis('equal')
plt.legend()
plt.show()